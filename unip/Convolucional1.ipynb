{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Redes Neurais Profundas - Exemplo\n",
    "\n",
    "## Classificador de cães e gatos\n",
    "\n",
    "Dada uma imagem que tem um cão ou gato, vamos ser capazes de dizer qual categoria ela está."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "\n",
    "from dataset_aula import MyDataset   # Classe que carrega dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'gpu'      # 'cpu'\n",
    "GPU_NUMBER = 0\n",
    "\n",
    "PREFIX = '/media/dpetrini/KINGSTON/Daniel/nova/data_cats_dogs_old'\n",
    "NUM_EPOCHS = 30\n",
    "MINI_BATCH = 4\n",
    "LR = 3e-4            # Learning rate - Taxa de aprendizado\n",
    "PRE_TRAINED = False\n",
    "NUM_WORKERS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar uma rede com duas camadas convolucionais (feature extraction) e 2 camadas lineares (classificadores).\n",
    "\n",
    "![title](images/RedeConvolucional.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedeConv(nn.Module):\n",
    "    \"\"\" Rede Convolucional de duas camadas \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RedeConv, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(  # Rede Convolucional para extrair features\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2), \n",
    "            nn.ReLU(inplace=True),          # função de ativação não linear\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            )\n",
    "        \n",
    "        self.classifier = nn.Sequential(         # Rede Neural Artificial para classificar\n",
    "            nn.Linear(32*54*54, 100),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcao que executa treino e validação por diversas épocas.\n",
    "\n",
    "def train_and_validate(model, loss_criterion, optimizer, \n",
    "                       train_data_loader, validation_data_loader, \n",
    "                       device, epochs=25, batch_size=1):\n",
    "\n",
    "    train_data_size = len(train_data_loader) * batch_size\n",
    "    val_data_size = len(validation_data_loader) * batch_size\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print('Epoch: {}/{}'.format(epoch+1, epochs))\n",
    "\n",
    "        model.train()       # set to training mode\n",
    "\n",
    "        #loss and acc for the epoch\n",
    "        train_loss, train_acc = 0.0, 0.0\n",
    "        validation_loss, validation_acc = 0.0, 0.0\n",
    "\n",
    "        for i, (inputs, labels) in enumerate(train_data_loader):  # no iterator com tam=bs\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)       # Aprendizagem supervisionada - ja tenho os resultados do treino\n",
    "\n",
    "            optimizer.zero_grad()                       # clean existing gradients\n",
    "            outputs = model(inputs)                     # forward pass\n",
    "            loss = loss_criterion(outputs, labels)      # compute loss\n",
    "            loss.backward()                             # backprop the gradients\n",
    "            optimizer.step()                            # update parameters\n",
    "            train_loss += loss.item() * inputs.size(0)  # compute the total loss for the batch & add\n",
    "\n",
    "            # compute the accuracy\n",
    "            acc = (torch.argmax(outputs, dim=1) == labels).float().sum()\n",
    "\n",
    "            # compute total accuracy in the whole batch and add to train_acc\n",
    "            train_acc += acc.item()\n",
    "\n",
    "        # validation - no gradient tracking needed\n",
    "        with torch.no_grad():\n",
    "\n",
    "            model.eval()        # set to evaluation mode\n",
    "\n",
    "            # validation loop\n",
    "            for j, (inputs, labels) in enumerate(validation_data_loader):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)                         # forward pass for validation\n",
    "                loss = loss_criterion(outputs, labels)\t        # compute loss\n",
    "                validation_loss += loss.item() * inputs.size(0) # compute the total loss for the batch & add\n",
    "\n",
    "                # calculcate validation acc\n",
    "                acc = (torch.argmax(outputs, dim=1) == labels).float().sum()\n",
    "\n",
    "                # compute total accuracy in the whole batch and addd to valid_acc\n",
    "                validation_acc += acc.item()\n",
    "\n",
    "        # fing average training loss and training accuracy\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "\n",
    "        # find average training loss and validation acc\n",
    "        avg_validation_loss = validation_loss/val_data_size\n",
    "        avg_validation_acc = validation_acc/val_data_size\n",
    "\n",
    "        epoch_end = time.time()\n",
    "\n",
    "        print('Epoch: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.2f}%, Validation: Loss: {:0.4f}, Accuracy: {:.2f}%, Time: {:.2f}s'.format(epoch+1, avg_train_loss, avg_train_acc*100, avg_validation_loss, avg_validation_acc*100, epoch_end-epoch_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(model):\n",
    "    \"\"\" good init for not pre-trained \"\"\"\n",
    "    print(\"Init weights with kaiming\")\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(m.weight)\n",
    "        elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RedeConv()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(model)\n",
    "\n",
    "\n",
    "if (DEVICE == \"gpu\") and torch.has_cudnn:\n",
    "    device = torch.device(\"cuda:{}\".format(GPU_NUMBER))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_paths = PREFIX+'/train'\n",
    "val_image_paths = PREFIX+'/val'\n",
    "test_image_paths = PREFIX+'/test'\n",
    "\n",
    "# Carrega datasets\n",
    "dataset_train = MyDataset(train_image_paths, train=True)\n",
    "dataset_val = MyDataset(val_image_paths, train=False)\n",
    "dataset_test = MyDataset(test_image_paths, train=False)\n",
    "\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=MINI_BATCH, shuffle=True)\n",
    "val_dataloader = DataLoader(dataset_val, batch_size=MINI_BATCH, shuffle=False)\n",
    "test_dataloader = DataLoader(dataset_test, batch_size=MINI_BATCH, shuffle=False)\n",
    "\n",
    "print('\\nSize train:', len(dataset_train), ' Size val: ', len(dataset_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrar exemplos do dataset\n",
    "def show_image(im, label, ax=None, figsize=(3, 3)):\n",
    "    if ax is None: _, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.axis('off')\n",
    "    ax.set_title(dataset_train.get_category(label))\n",
    "    #print(im.shape, im.type())\n",
    "    im = im.permute(1, 2, 0)\n",
    "    ax.imshow(im)\n",
    "\n",
    "\n",
    "def show_batch(x, label, c=4, r=None, figsize=None):\n",
    "    n = len(x)\n",
    "    cont = 0\n",
    "    if r is None: r = int(math.ceil(n/c))\n",
    "    if figsize is None: figsize = (c*3, r*3)\n",
    "    fig, axes = plt.subplots(r, c, figsize=figsize)\n",
    "    for xi, ax in zip(x, axes.flat):\n",
    "        show_image(xi, label[cont], ax)\n",
    "        cont += 1\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show some samples\n",
    "img, label = next(iter(train_dataloader))\n",
    "show_batch(img[0:20], label, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_validate(model, loss_func, optimizer, train_dataloader, val_dataloader, device,\n",
    "                   epochs=NUM_EPOCHS, batch_size=MINI_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados:\n",
    "    RedeConv 1: 70.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos melhorar esse resultado?\n",
    "\n",
    "Vamos criar uma rede mais profunda, com uma camada convolucional a mais.\n",
    "\n",
    "![title](images/RedeConvolucionalMaisProfunda.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RedeConvMaisProfunda(nn.Module):\n",
    "    \"\"\" Rede com uma camada convolucional a mais \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RedeConvMaisProfunda, self).__init__()\n",
    "\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.ReLU(inplace=True)                        \n",
    "            )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64*26*26, 100),\n",
    "            nn.Linear(100, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = RedeConvMaisProfunda()\n",
    "\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize(model2)\n",
    "\n",
    "\n",
    "if (DEVICE == \"gpu\") and torch.has_cudnn:\n",
    "    device = torch.device(\"cuda:{}\".format(GPU_NUMBER))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_and_validate(model2, loss_func, optimizer, train_dataloader, val_dataloader, device,\n",
    "#                   epochs=NUM_EPOCHS, batch_size=MINI_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando uma bibliteca com as principais funções\n",
    "#\n",
    "# http://www.github.com/dpetrini/nova\n",
    "#\n",
    "# Existe um exemplo similar com instruções para rodar completo, neste repositório\n",
    "\n",
    "from trainer import Trainer\n",
    "\n",
    "optim_args = {}\n",
    "\n",
    "train_config = {\n",
    "    'num_epochs': NUM_EPOCHS,\n",
    "    'batch_size': MINI_BATCH,\n",
    "    'name': 'aula',\n",
    "    'title': 'Cats & Dogs Classifier',\n",
    "    # 'features': ['auc'],\n",
    "}\n",
    "\n",
    "session = Trainer(model2, train_dataloader, val_dataloader, loss_func,\n",
    "                  optimizer, optim_args, device, train_config)\n",
    "\n",
    "# train the model\n",
    "session.train_and_validate()\n",
    "\n",
    "print(\"\\nRunning models in test set...\")\n",
    "session.run_test(test_dataloader, \"normal\")\n",
    "session.run_test(test_dataloader, \"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
